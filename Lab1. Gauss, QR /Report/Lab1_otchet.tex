\documentclass[12pt,a4paper]{article}

\usepackage[cp1251]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}
\usepackage{hyperref}
\usepackage[footnotes,oglav,spisok,boldsect,eqwhole,remarks,kursrab, hyperprint] {project}
\usepackage{graphicx}


\newcommand{\sv}{$\blacktriangleleft$ \textit{Решение}} %sv - solve
\newcommand{\matr}[4]{ \begin{pmatrix}
	#1 & #2 \\
	#3 & #4 
\end{pmatrix}}

\begin{document}
\cover{Методы вычислений}{Прямые методы решения систем линейных алгебраических уравнений.}{студенты группы ФН12-51}{Поддерегин~Осип и \: Чаплинская~Надежда}{\centerline{\Large{Вариант 18; 22}}}{}{}{}{2019}
%\tableofcontents
\newpage

\section*{Ответы на контрольные вопросы}
\begin{enumerate}
\item \textit Каковы условия применимости метода Гаусса с выбором и без выбора ведущего элемента?\\
\sv. Без выбора. В таком случае, на каждом шаге алгоритма текущий диагональный элемент должен быть отличен от нуля: $a_{ii}^{(i-1)} \neq 0$, $i = 1,2, ... , n$, где верхний индекс показывает текущий шаг алгоритма. Из этого условия следует невырожденность исходной матрицы. Однако хотелось бы знать изначально, а не в ходе реализации алгоритма, можно ли к данной матрице применить метод Гаусса без выбора ведущего элемента. Докажем, что требуемое нами условие эквивалентно неравенству нулю угловых миноров исходной матрицы А. 

Пусть все угловые миноры не равны нулю. Из неравенства нулю первого углового минора следует неравенство нулю элемента $a_{11}$, а значит и возможность реализовать первый шаг алгоритма. Рассмотрим второй угловой минор:
$$ \left | \begin{matrix}
		a_{11} & a_{12} \\
	a_{21} & a_{22}
\end{matrix} \right | \neq 0
$$
Помним, что определитель матрицы не меняется при элементарном преобразовании, соответствующем замене строки на линейную комбинацию ее самой с другой строкой матрицы.
Следовательно, 
$${ \left| \begin{matrix}
	a_{11}^{(1)} & a_{12}^{(1)} \\
	0 & a_{22}^{(1)}
\end{matrix} \right|} \neq 0$$
а значит, $a_{22}^{(1)} \neq 0$

Рассмотрим минор порядка $k$. Заметим (проводя аналогичные рассуждения), что мы имели возможность реализовать $(k-1)$ шагов алгоритма. Cледовательно, $ a^{(k-1)}_{ij} = 0 \hspace{5pt} \forall i=2 \ldots k, \hspace{3pt} j = 1 \ldots (i-1) $. Из этого заключаем, что и $ a^{(k-1)}_{kk} \neq 0$ $\forall k = 1 \ldots n$, иначе определитель равнялся бы нулю.

 Аналогично рассуждая в обратном направлении, получим, что из $a_{kk}\neq 0$ следует неравенство нулю всех угловых миноров. 
Таким образом, условием применимости метода Гаусса без выбора главного элемента является неравенство нулю всех угловых миноров матрицы А.
\\С выбором. Для случая реализации метода Гаусса с выбором главного элемента необходимо и достаточно потребовать невырожденность матрицы А.\\
\\
\item \textit{Докажите, что если $\det A \ne 0$, то при выборе главного элемента в столбце среди элементов, лежащих не выше главной диагонали, всегда найдется хотя бы один элемент, отличный от нуля.}\\
\sv. 
Докажем, что $a_{ik} \neq 0  \hspace{6pt} \forall k \hspace{6pt} \forall i = k, k+1, ..., n$. 
Проведем индукцию по $k$. 

База индукции ($k=1$). Пусть $a_{i1} = 0  \hspace{6pt}  \forall i = 1, 2, ..., n$. Тогда $\det A \neq 0$ - противоречие.

Шаг индукции. Пусть утверждение верно для $(k-1)$. Рассмотрим столбец под номером $k$.
От противного: пусть $a_{ik} = 0  \hspace{6pt}  \forall i = k, k+1, ..., n$\\
Рассмотрим столбцы с номерами, меньшими чем k (будем интерпретировать их как вектора исходного пространства). Ни один из них не может иметь отличную от нуля k-ю координату (поскольку до этого имели возможность реализовывать алгоритм). Добавим к  данной системе столбцов k-й столбец, который также, по условию, имеет нулевую k-ую координату. Таким образом, получим систему k векторов, заведомо лежащих в подпространстве размерности, не выше чем (k-1). Такая система линейно зависима, а следовательно, определитель $\det{A} = 0$. Противоречие.\\
\\

\item \textit Что такое число обусловленности и что оно характеризует? Имеется ли связь между обусловленностью и величиной определителя матрицы? Как влияет выбор нормы матрицы на оценку числа обусловленности?\\
\sv. 
Рассмотрим матрицу 
$$ A = 
\left(\begin{matrix}
	1 & x \\
	0 & 1
\end{matrix} \right)
$$
Площадь S параллелограмма, натянутого на  вектора  $ \vec{A_1} = (1, 0)^T$,  векторами $ \vec{A_1} = (x, 1)^T$, равна $$
\det{A} = 1 = |A_1||A_2|sin\phi
$$

 Отсюда $$sin\phi = \frac{1}{\sqrt{x^2 + 1}} $$
 Заметим, что решением этого уравнения является функция $x = x(\phi) = ctg\phi $
 Следовательно, можно считать
 $$ A = 
\left(\begin{matrix}
	1 & ctg\phi \\
	0 & 1
\end{matrix} \right)
$$
Большое число обусловленности получим при малом угле (вектора будут близки к линейно зависимым). Следовательно, в качестве x можно взять соответствующий малому углу большой котангенс. Таким образом, получили плохо обусловленную матрицу с единичным определителем.
\\

\item \textit Применимо ли понятие числа обусловленности к вырожденным матрицам?\\
\sv. Имеем в таком случае бесконечное множество решений, принадлежащих какому-либо подпространству. Условимся брать решение из нужного подпространства, а именно: пусть для СЛАУ $Ax=b$ решением будет являться вектор-столбец X с k-ой нулевой координатой, тогда для СЛАУ $Ax'=(b+\delta b)$ будем брать решение X' с k+1-ой нулевой координатой, то есть получим при малых возмущениях правой части большую погрешность решения.\\
Рассмотрим оценку снизу числа обусловленности матрицы А:
$cond A \geq \frac{\parallel \delta x \parallel}{\parallel \delta b \parallel}$. Если выбирать решения способом, описанном выше, то $\parallel\delta x\parallel$ будет ограничена при любом выборе погрешности правой части.
Тогда для любого сколько угодоно большого $$\epsilon > 0  \hspace{6pt} \exists \parallel \delta b \parallel : cond A \geq  \frac{\parallel \delta x \parallel}{\parallel \delta b \parallel} > \epsilon$$
То есть число обусловленности превосходит любое наперед заданное число. Обозначив $cond A = \infty$ для таких случаев, получаем, что понятие числа обусловленности применимо к вырожденным матрицам.\\
\\
\item \textit В каких случаях целесообразно использовать метод Гаусса, а в каких — методы, основанные на факторизации матрицы?\\
\sv. Если в приоритете время, используем метод Гаусса (меньшее число операций). Если же предстоит решать одну и ту же систему с разной правой частью, то целесообразней использовать QR разложение. \\
\\
\\
\end{enumerate}


\end{document} 
